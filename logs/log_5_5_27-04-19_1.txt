batch_size 16 <class 'int'>
image_height 28 <class 'int'>
image_width 28 <class 'int'>
image_channels 1 <class 'int'>
reset_stored_filepaths False <class 'bool'>
reverse_channels False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-3, -2] <class 'list'>
train_val_test_split [0.70918052988, 0.03080714725, 0.2606284658] <class 'list'>
samples_per_iter 1 <class 'int'>
labels_as_int False <class 'bool'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
max_models_to_save 5 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path datasets/datasets/omniglot_dataset
dataset_path datasets/omniglot_dataset <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name omniglot_maml_omniglot_5_way_5_shot_maml_1 <class 'str'>
architecture_name None <class 'NoneType'>
continue_from_epoch latest <class 'str'>
dropout_rate_value 0.0 <class 'float'>
num_target_samples 1 <class 'int'>
second_order True <class 'bool'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 500 <class 'int'>
min_learning_rate 1e-05 <class 'float'>
meta_learning_rate 0.001 <class 'float'>
meta_opt_bn False <class 'bool'>
task_learning_rate -1 <class 'int'>
norm_layer batch_norm <class 'str'>
max_pooling True <class 'bool'>
per_step_bn_statistics False <class 'bool'>
num_classes_per_set 5 <class 'int'>
cnn_num_blocks 4 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 5 <class 'int'>
cnn_num_filters 64 <class 'int'>
cnn_blocks_per_stage 1 <class 'int'>
num_samples_per_class 5 <class 'int'>
name_of_args_json_file experiment_config/omniglot_maml_omniglot_5_way_5_shot_maml_1.json <class 'str'>
train_seed 1 <class 'int'>
val_seed 1 <class 'int'>
load_from_npz_files False <class 'bool'>
sets_are_pre_split False <class 'bool'>
load_into_memory True <class 'bool'>
init_inner_loop_learning_rate 0.1 <class 'float'>
train_in_stages False <class 'bool'>
multi_step_loss_num_epochs 10 <class 'int'>
minimum_per_task_contribution 0.01 <class 'float'>
num_evaluation_tasks 600 <class 'int'>
learnable_per_layer_per_step_inner_loop_learning_rate False <class 'bool'>
enable_inner_loop_optimizable_bn_params False <class 'bool'>
evaluate_on_test_set_only False <class 'bool'>
learnable_batch_norm_momentum False <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
learnable_bn_gamma True <class 'bool'>
learnable_bn_beta True <class 'bool'>
weight_decay 0.0 <class 'float'>
total_epochs_before_pause 10 <class 'int'>
first_order_to_second_order_epoch -1 <class 'int'>
num_stages 4 <class 'int'>
conv_padding 1 <class 'int'>
use_multi_step_loss_optimization False <class 'bool'>
Using max pooling
torch.Size([2, 64, 28, 28])
torch.Size([2, 64, 14, 14])
torch.Size([2, 64, 7, 7])
torch.Size([2, 64, 3, 3])
VGGNetwork build torch.Size([2, 5])
meta network params
layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
layer_dict.conv0.conv.bias torch.Size([64])
layer_dict.conv0.norm_layer.running_mean torch.Size([64])
layer_dict.conv0.norm_layer.running_var torch.Size([64])
layer_dict.conv0.norm_layer.bias torch.Size([64])
layer_dict.conv0.norm_layer.weight torch.Size([64])
layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv1.conv.bias torch.Size([64])
layer_dict.conv1.norm_layer.running_mean torch.Size([64])
layer_dict.conv1.norm_layer.running_var torch.Size([64])
layer_dict.conv1.norm_layer.bias torch.Size([64])
layer_dict.conv1.norm_layer.weight torch.Size([64])
layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv2.conv.bias torch.Size([64])
layer_dict.conv2.norm_layer.running_mean torch.Size([64])
layer_dict.conv2.norm_layer.running_var torch.Size([64])
layer_dict.conv2.norm_layer.bias torch.Size([64])
layer_dict.conv2.norm_layer.weight torch.Size([64])
layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv3.conv.bias torch.Size([64])
layer_dict.conv3.norm_layer.running_mean torch.Size([64])
layer_dict.conv3.norm_layer.running_var torch.Size([64])
layer_dict.conv3.norm_layer.bias torch.Size([64])
layer_dict.conv3.norm_layer.weight torch.Size([64])
layer_dict.linear.weights torch.Size([5, 64])
layer_dict.linear.bias torch.Size([5])
Inner Loop parameters
classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
classifier.layer_dict.conv0.conv.bias torch.Size([64])
classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv1.conv.bias torch.Size([64])
classifier.layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv2.conv.bias torch.Size([64])
classifier.layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv3.conv.bias torch.Size([64])
classifier.layer_dict.linear.weights torch.Size([5, 64])
classifier.layer_dict.linear.bias torch.Size([5])
Outer Loop parameters
classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
classifier.layer_dict.conv0.conv.bias torch.Size([64])
classifier.layer_dict.conv0.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv0.norm_layer.weight torch.Size([64])
classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv1.conv.bias torch.Size([64])
classifier.layer_dict.conv1.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv1.norm_layer.weight torch.Size([64])
classifier.layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv2.conv.bias torch.Size([64])
classifier.layer_dict.conv2.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv2.norm_layer.weight torch.Size([64])
classifier.layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv3.conv.bias torch.Size([64])
classifier.layer_dict.conv3.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv3.norm_layer.weight torch.Size([64])
classifier.layer_dict.linear.weights torch.Size([5, 64])
classifier.layer_dict.linear.bias torch.Size([5])
datasets/omniglot_dataset
count stuff________________________________________ 32460
file count is correct
attempting to find existing checkpoint
1150 1200 1623
Loading data into RAM
Currently loading into memory the train set
Currently loading into memory the val set
Currently loading into memory the test set
data {'train': 23000, 'val': 1000, 'test': 8460}
train_seed 128038, val_seed: 128038, at start time
10000 50000
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 21 -> train_loss_mean: 0.2304, train_loss_std: 0.3961, train_accuracy_mean: 0.9951, train_accuracy_std: 0.0081, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.3512, val_loss_std: 0.3738, val_accuracy_mean: 0.9932, val_accuracy_std: 0.0069, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 22 -> train_loss_mean: 0.1648, train_loss_std: 0.3152, train_accuracy_mean: 0.9968, train_accuracy_std: 0.0064, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.3177, val_loss_std: 0.4872, val_accuracy_mean: 0.9929, val_accuracy_std: 0.0107, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 23 -> train_loss_mean: 0.1986, train_loss_std: 0.4088, train_accuracy_mean: 0.9964, train_accuracy_std: 0.0076, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.3375, val_loss_std: 0.4612, val_accuracy_mean: 0.9936, val_accuracy_std: 0.0118, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.9942567567567566
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 24 -> train_loss_mean: 0.1751, train_loss_std: 0.3008, train_accuracy_mean: 0.9964, train_accuracy_std: 0.0068, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.2698, val_loss_std: 0.3096, val_accuracy_mean: 0.9943, val_accuracy_std: 0.0069, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.9952702702702702
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 25 -> train_loss_mean: 0.1333, train_loss_std: 0.2589, train_accuracy_mean: 0.9973, train_accuracy_std: 0.0063, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.2091, val_loss_std: 0.2975, val_accuracy_mean: 0.9953, val_accuracy_std: 0.0079, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 26 -> train_loss_mean: 0.1862, train_loss_std: 0.4181, train_accuracy_mean: 0.9966, train_accuracy_std: 0.0076, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.2320, val_loss_std: 0.3659, val_accuracy_mean: 0.9939, val_accuracy_std: 0.0099, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 27 -> train_loss_mean: 0.2963, train_loss_std: 0.4261, train_accuracy_mean: 0.9941, train_accuracy_std: 0.0097, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.3023, val_loss_std: 0.4230, val_accuracy_mean: 0.9932, val_accuracy_std: 0.0095, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 28 -> train_loss_mean: 0.2100, train_loss_std: 0.3500, train_accuracy_mean: 0.9961, train_accuracy_std: 0.0070, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.2457, val_loss_std: 0.3518, val_accuracy_mean: 0.9943, val_accuracy_std: 0.0090, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 29 -> train_loss_mean: 0.1877, train_loss_std: 0.3050, train_accuracy_mean: 0.9960, train_accuracy_std: 0.0073, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.2841, val_loss_std: 0.3160, val_accuracy_mean: 0.9922, val_accuracy_std: 0.0106, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_5_shot_maml_1/saved_models
epoch 30 -> train_loss_mean: 0.1982, train_loss_std: 0.3383, train_accuracy_mean: 0.9961, train_accuracy_std: 0.0074, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.2392, val_loss_std: 0.3428, val_accuracy_mean: 0.9953, val_accuracy_std: 0.0079, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
train_seed 288038, val_seed: 128038, at pause time
