batch_size 16 <class 'int'>
image_height 28 <class 'int'>
image_width 28 <class 'int'>
image_channels 1 <class 'int'>
reset_stored_filepaths False <class 'bool'>
reverse_channels False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-3, -2] <class 'list'>
train_val_test_split [0.70918052988, 0.03080714725, 0.2606284658] <class 'list'>
samples_per_iter 1 <class 'int'>
labels_as_int False <class 'bool'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
max_models_to_save 5 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path datasets/datasets/omniglot_dataset
dataset_path datasets/omniglot_dataset <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name omniglot_maml_omniglot_5_way_1_shot_maml_2 <class 'str'>
architecture_name None <class 'NoneType'>
continue_from_epoch latest <class 'str'>
dropout_rate_value 0.0 <class 'float'>
num_target_samples 1 <class 'int'>
second_order True <class 'bool'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 500 <class 'int'>
min_learning_rate 1e-05 <class 'float'>
meta_learning_rate 0.001 <class 'float'>
meta_opt_bn False <class 'bool'>
task_learning_rate -1 <class 'int'>
norm_layer batch_norm <class 'str'>
max_pooling True <class 'bool'>
per_step_bn_statistics False <class 'bool'>
num_classes_per_set 5 <class 'int'>
cnn_num_blocks 4 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 5 <class 'int'>
cnn_num_filters 64 <class 'int'>
cnn_blocks_per_stage 1 <class 'int'>
num_samples_per_class 1 <class 'int'>
name_of_args_json_file experiment_config/omniglot_maml_omniglot_5_way_1_shot_maml_2.json <class 'str'>
train_seed 2 <class 'int'>
val_seed 2 <class 'int'>
load_from_npz_files False <class 'bool'>
sets_are_pre_split False <class 'bool'>
load_into_memory True <class 'bool'>
init_inner_loop_learning_rate 0.1 <class 'float'>
train_in_stages False <class 'bool'>
multi_step_loss_num_epochs 10 <class 'int'>
minimum_per_task_contribution 0.01 <class 'float'>
num_evaluation_tasks 600 <class 'int'>
learnable_per_layer_per_step_inner_loop_learning_rate False <class 'bool'>
enable_inner_loop_optimizable_bn_params False <class 'bool'>
evaluate_on_test_set_only False <class 'bool'>
learnable_batch_norm_momentum False <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
learnable_bn_gamma True <class 'bool'>
learnable_bn_beta True <class 'bool'>
weight_decay 0.0 <class 'float'>
total_epochs_before_pause 10 <class 'int'>
first_order_to_second_order_epoch -1 <class 'int'>
num_stages 4 <class 'int'>
conv_padding 1 <class 'int'>
use_multi_step_loss_optimization False <class 'bool'>
Using max pooling
torch.Size([2, 64, 28, 28])
torch.Size([2, 64, 14, 14])
torch.Size([2, 64, 7, 7])
torch.Size([2, 64, 3, 3])
VGGNetwork build torch.Size([2, 5])
meta network params
layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
layer_dict.conv0.conv.bias torch.Size([64])
layer_dict.conv0.norm_layer.running_mean torch.Size([64])
layer_dict.conv0.norm_layer.running_var torch.Size([64])
layer_dict.conv0.norm_layer.bias torch.Size([64])
layer_dict.conv0.norm_layer.weight torch.Size([64])
layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv1.conv.bias torch.Size([64])
layer_dict.conv1.norm_layer.running_mean torch.Size([64])
layer_dict.conv1.norm_layer.running_var torch.Size([64])
layer_dict.conv1.norm_layer.bias torch.Size([64])
layer_dict.conv1.norm_layer.weight torch.Size([64])
layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv2.conv.bias torch.Size([64])
layer_dict.conv2.norm_layer.running_mean torch.Size([64])
layer_dict.conv2.norm_layer.running_var torch.Size([64])
layer_dict.conv2.norm_layer.bias torch.Size([64])
layer_dict.conv2.norm_layer.weight torch.Size([64])
layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv3.conv.bias torch.Size([64])
layer_dict.conv3.norm_layer.running_mean torch.Size([64])
layer_dict.conv3.norm_layer.running_var torch.Size([64])
layer_dict.conv3.norm_layer.bias torch.Size([64])
layer_dict.conv3.norm_layer.weight torch.Size([64])
layer_dict.linear.weights torch.Size([5, 64])
layer_dict.linear.bias torch.Size([5])
Inner Loop parameters
classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
classifier.layer_dict.conv0.conv.bias torch.Size([64])
classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv1.conv.bias torch.Size([64])
classifier.layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv2.conv.bias torch.Size([64])
classifier.layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv3.conv.bias torch.Size([64])
classifier.layer_dict.linear.weights torch.Size([5, 64])
classifier.layer_dict.linear.bias torch.Size([5])
Outer Loop parameters
classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
classifier.layer_dict.conv0.conv.bias torch.Size([64])
classifier.layer_dict.conv0.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv0.norm_layer.weight torch.Size([64])
classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv1.conv.bias torch.Size([64])
classifier.layer_dict.conv1.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv1.norm_layer.weight torch.Size([64])
classifier.layer_dict.conv2.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv2.conv.bias torch.Size([64])
classifier.layer_dict.conv2.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv2.norm_layer.weight torch.Size([64])
classifier.layer_dict.conv3.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv3.conv.bias torch.Size([64])
classifier.layer_dict.conv3.norm_layer.bias torch.Size([64])
classifier.layer_dict.conv3.norm_layer.weight torch.Size([64])
classifier.layer_dict.linear.weights torch.Size([5, 64])
classifier.layer_dict.linear.bias torch.Size([5])
datasets/omniglot_dataset
count stuff________________________________________ 32460
file count is correct
attempting to find existing checkpoint
1150 1200 1623
Loading data into RAM
Currently loading into memory the train set
Currently loading into memory the val set
Currently loading into memory the test set
data {'train': 23000, 'val': 1000, 'test': 8460}
train_seed 875689, val_seed: 875689, at start time
5000 50000
Best validation accuracy 0.9780405405405403
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 11 -> train_loss_mean: 0.8809, train_loss_std: 0.5297, train_accuracy_mean: 0.9825, train_accuracy_std: 0.0152, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 1.0914, val_loss_std: 0.6302, val_accuracy_mean: 0.9780, val_accuracy_std: 0.0173, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 12 -> train_loss_mean: 0.8694, train_loss_std: 0.5507, train_accuracy_mean: 0.9829, train_accuracy_std: 0.0153, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 1.2715, val_loss_std: 0.6433, val_accuracy_mean: 0.9713, val_accuracy_std: 0.0221, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 13 -> train_loss_mean: 0.6925, train_loss_std: 0.4487, train_accuracy_mean: 0.9862, train_accuracy_std: 0.0132, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 1.1091, val_loss_std: 0.7530, val_accuracy_mean: 0.9767, val_accuracy_std: 0.0193, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.981081081081081
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 14 -> train_loss_mean: 0.6617, train_loss_std: 0.4732, train_accuracy_mean: 0.9868, train_accuracy_std: 0.0136, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.9547, val_loss_std: 0.6573, val_accuracy_mean: 0.9811, val_accuracy_std: 0.0181, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 15 -> train_loss_mean: 0.5884, train_loss_std: 0.4261, train_accuracy_mean: 0.9889, train_accuracy_std: 0.0120, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.9243, val_loss_std: 0.6477, val_accuracy_mean: 0.9804, val_accuracy_std: 0.0166, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 16 -> train_loss_mean: 0.5777, train_loss_std: 0.4054, train_accuracy_mean: 0.9884, train_accuracy_std: 0.0119, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.9385, val_loss_std: 0.7334, val_accuracy_mean: 0.9797, val_accuracy_std: 0.0210, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 17 -> train_loss_mean: 0.5398, train_loss_std: 0.4350, train_accuracy_mean: 0.9896, train_accuracy_std: 0.0120, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.9237, val_loss_std: 0.6285, val_accuracy_mean: 0.9811, val_accuracy_std: 0.0166, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 18 -> train_loss_mean: 0.5295, train_loss_std: 0.4183, train_accuracy_mean: 0.9897, train_accuracy_std: 0.0116, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.8748, val_loss_std: 0.6266, val_accuracy_mean: 0.9801, val_accuracy_std: 0.0183, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.9817567567567567
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 19 -> train_loss_mean: 0.4625, train_loss_std: 0.3841, train_accuracy_mean: 0.9907, train_accuracy_std: 0.0111, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.7900, val_loss_std: 0.5143, val_accuracy_mean: 0.9818, val_accuracy_std: 0.0150, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.9820945945945946
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml_omniglot_5_way_1_shot_maml_2/saved_models
epoch 20 -> train_loss_mean: 0.4818, train_loss_std: 0.4166, train_accuracy_mean: 0.9900, train_accuracy_std: 0.0121, train_loss_importance_vector_0_mean: 0.0060, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0060, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0060, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0060, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9760, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 0.8708, val_loss_std: 0.5385, val_accuracy_mean: 0.9821, val_accuracy_std: 0.0158, val_loss_importance_vector_0_mean: 0.0060, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0060, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0060, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0060, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9760, val_loss_importance_vector_4_std: 0.0000, 
train_seed 955689, val_seed: 875689, at pause time
