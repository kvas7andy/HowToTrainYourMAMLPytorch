batch_size 16 <class 'int'>
image_height 28 <class 'int'>
image_width 28 <class 'int'>
image_channels 1 <class 'int'>
reset_stored_filepaths False <class 'bool'>
reverse_channels False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-3, -2] <class 'list'>
train_val_test_split [0.70918052988, 0.03080714725, 0.2606284658] <class 'list'>
samples_per_iter 1 <class 'int'>
labels_as_int False <class 'bool'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
max_models_to_save 5 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path datasets/datasets/omniglot_dataset
dataset_path datasets/omniglot_dataset <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2 <class 'str'>
architecture_name None <class 'NoneType'>
continue_from_epoch latest <class 'str'>
dropout_rate_value 0.0 <class 'float'>
num_target_samples 1 <class 'int'>
second_order True <class 'bool'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 500 <class 'int'>
min_learning_rate 1e-05 <class 'float'>
meta_learning_rate 0.001 <class 'float'>
meta_opt_bn False <class 'bool'>
task_learning_rate -1 <class 'int'>
norm_layer batch_norm <class 'str'>
max_pooling True <class 'bool'>
per_step_bn_statistics True <class 'bool'>
num_classes_per_set 5 <class 'int'>
cnn_num_blocks 4 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 5 <class 'int'>
cnn_num_filters 64 <class 'int'>
cnn_blocks_per_stage 1 <class 'int'>
num_samples_per_class 1 <class 'int'>
name_of_args_json_file experiment_config/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2.json <class 'str'>
train_seed 1 <class 'int'>
val_seed 1 <class 'int'>
load_from_npz_files False <class 'bool'>
sets_are_pre_split False <class 'bool'>
load_into_memory True <class 'bool'>
init_inner_loop_learning_rate 0.1 <class 'float'>
train_in_stages False <class 'bool'>
multi_step_loss_num_epochs 10 <class 'int'>
minimum_per_task_contribution 0.01 <class 'float'>
num_evaluation_tasks 600 <class 'int'>
learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_bn_params False <class 'bool'>
evaluate_on_test_set_only False <class 'bool'>
learnable_batch_norm_momentum False <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
learnable_bn_gamma True <class 'bool'>
learnable_bn_beta True <class 'bool'>
weight_decay 0.0 <class 'float'>
total_epochs_before_pause 10 <class 'int'>
first_order_to_second_order_epoch -1 <class 'int'>
num_stages 2 <class 'int'>
conv_padding 1 <class 'int'>
use_multi_step_loss_optimization True <class 'bool'>
Using max pooling
torch.Size([2, 64, 28, 28])
torch.Size([2, 64, 14, 14])
VGGNetwork build torch.Size([2, 5])
meta network params
layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
layer_dict.conv0.conv.bias torch.Size([64])
layer_dict.conv0.norm_layer.running_mean torch.Size([5, 64])
layer_dict.conv0.norm_layer.running_var torch.Size([5, 64])
layer_dict.conv0.norm_layer.bias torch.Size([5, 64])
layer_dict.conv0.norm_layer.weight torch.Size([5, 64])
layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
layer_dict.conv1.conv.bias torch.Size([64])
layer_dict.conv1.norm_layer.running_mean torch.Size([5, 64])
layer_dict.conv1.norm_layer.running_var torch.Size([5, 64])
layer_dict.conv1.norm_layer.bias torch.Size([5, 64])
layer_dict.conv1.norm_layer.weight torch.Size([5, 64])
layer_dict.linear.weights torch.Size([5, 3136])
layer_dict.linear.bias torch.Size([5])
Inner Loop parameters
task_learning_rate torch.Size([5, 6])
classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
classifier.layer_dict.conv0.conv.bias torch.Size([64])
classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv1.conv.bias torch.Size([64])
classifier.layer_dict.linear.weights torch.Size([5, 3136])
classifier.layer_dict.linear.bias torch.Size([5])
Outer Loop parameters
task_learning_rate torch.Size([5, 6])
classifier.layer_dict.conv0.conv.weight torch.Size([64, 1, 3, 3])
classifier.layer_dict.conv0.conv.bias torch.Size([64])
classifier.layer_dict.conv0.norm_layer.bias torch.Size([5, 64])
classifier.layer_dict.conv0.norm_layer.weight torch.Size([5, 64])
classifier.layer_dict.conv1.conv.weight torch.Size([64, 64, 3, 3])
classifier.layer_dict.conv1.conv.bias torch.Size([64])
classifier.layer_dict.conv1.norm_layer.bias torch.Size([5, 64])
classifier.layer_dict.conv1.norm_layer.weight torch.Size([5, 64])
classifier.layer_dict.linear.weights torch.Size([5, 3136])
classifier.layer_dict.linear.bias torch.Size([5])
datasets/omniglot_dataset
count stuff________________________________________ 32460
file count is correct
attempting to find existing checkpoint
1150 1200 1623
Loading data into RAM
Currently loading into memory the train set
Currently loading into memory the val set
Currently loading into memory the test set
data {'train': 23000, 'val': 1000, 'test': 8460}
train_seed 128038, val_seed: 128038, at start time
0 50000
shape of data torch.Size([16, 5, 1, 1, 28, 28]) torch.Size([16, 5, 1, 1, 28, 28]) torch.Size([16, 5, 1]) torch.Size([16, 5, 1])
Best validation accuracy 0.5543918918918919
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 1 -> train_loss_mean: 100.9833, train_loss_std: 142.6052, train_accuracy_mean: 0.5607, train_accuracy_std: 0.0918, train_loss_importance_vector_0_mean: 0.2000, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.2000, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.2000, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.2000, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.2000, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 19.1734, val_loss_std: 1.5995, val_accuracy_mean: 0.5544, val_accuracy_std: 0.0609, val_loss_importance_vector_0_mean: 0.2000, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.2000, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.2000, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.2000, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.2000, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.6037162162162162
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 2 -> train_loss_mean: 19.0388, train_loss_std: 1.3395, train_accuracy_mean: 0.5957, train_accuracy_std: 0.0558, train_loss_importance_vector_0_mean: 0.1800, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.1800, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.1800, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.1800, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.2800, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 17.8515, val_loss_std: 1.4824, val_accuracy_mean: 0.6037, val_accuracy_std: 0.0515, val_loss_importance_vector_0_mean: 0.1800, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.1800, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.1800, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.1800, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.2800, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.6253378378378378
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 3 -> train_loss_mean: 18.0004, train_loss_std: 1.2902, train_accuracy_mean: 0.6252, train_accuracy_std: 0.0500, train_loss_importance_vector_0_mean: 0.1600, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.1600, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.1600, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.1600, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.3600, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 17.0087, val_loss_std: 1.4341, val_accuracy_mean: 0.6253, val_accuracy_std: 0.0558, val_loss_importance_vector_0_mean: 0.1600, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.1600, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.1600, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.1600, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.3600, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.6456081081081081
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 4 -> train_loss_mean: 17.0253, train_loss_std: 1.3840, train_accuracy_mean: 0.6480, train_accuracy_std: 0.0556, train_loss_importance_vector_0_mean: 0.1400, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.1400, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.1400, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.1400, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.4400, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 16.1781, val_loss_std: 1.4264, val_accuracy_mean: 0.6456, val_accuracy_std: 0.0430, val_loss_importance_vector_0_mean: 0.1400, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.1400, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.1400, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.1400, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.4400, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.6709459459459458
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 5 -> train_loss_mean: 16.0047, train_loss_std: 1.4167, train_accuracy_mean: 0.6742, train_accuracy_std: 0.0531, train_loss_importance_vector_0_mean: 0.1200, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.1200, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.1200, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.1200, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.5200, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 14.9964, val_loss_std: 1.4608, val_accuracy_mean: 0.6709, val_accuracy_std: 0.0452, val_loss_importance_vector_0_mean: 0.1200, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.1200, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.1200, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.1200, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.5200, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.7013513513513513
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 6 -> train_loss_mean: 14.7806, train_loss_std: 1.4496, train_accuracy_mean: 0.7005, train_accuracy_std: 0.0530, train_loss_importance_vector_0_mean: 0.1000, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.1000, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.1000, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.1000, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.6000, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 13.5723, val_loss_std: 1.3987, val_accuracy_mean: 0.7014, val_accuracy_std: 0.0469, val_loss_importance_vector_0_mean: 0.1000, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.1000, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.1000, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.1000, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.6000, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.739527027027027
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 7 -> train_loss_mean: 13.3835, train_loss_std: 1.4358, train_accuracy_mean: 0.7344, train_accuracy_std: 0.0495, train_loss_importance_vector_0_mean: 0.0800, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0800, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0800, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0800, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.6800, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 11.8045, val_loss_std: 1.3854, val_accuracy_mean: 0.7395, val_accuracy_std: 0.0447, val_loss_importance_vector_0_mean: 0.0800, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0800, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0800, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0800, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.6800, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.7655405405405407
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 8 -> train_loss_mean: 12.3487, train_loss_std: 2.1317, train_accuracy_mean: 0.7551, train_accuracy_std: 0.0538, train_loss_importance_vector_0_mean: 0.0600, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0600, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0600, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0600, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.7600, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 10.6252, val_loss_std: 1.4267, val_accuracy_mean: 0.7655, val_accuracy_std: 0.0449, val_loss_importance_vector_0_mean: 0.0600, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0600, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0600, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0600, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.7600, val_loss_importance_vector_4_std: 0.0000, 
Best validation accuracy 0.789527027027027
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 9 -> train_loss_mean: 10.5137, train_loss_std: 1.3246, train_accuracy_mean: 0.7891, train_accuracy_std: 0.0436, train_loss_importance_vector_0_mean: 0.0400, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0400, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0400, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0400, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.8400, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 9.9823, val_loss_std: 1.5367, val_accuracy_mean: 0.7895, val_accuracy_std: 0.0472, val_loss_importance_vector_0_mean: 0.0400, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0400, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0400, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0400, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.8400, val_loss_importance_vector_4_std: 0.0000, 
saved models to /home/akvasov/repos/HowToTrainYourMAMLPytorch/omniglot_maml++_omniglot_5_way_1_shot_maml_1_ns2/saved_models
epoch 10 -> train_loss_mean: 9.6165, train_loss_std: 1.5113, train_accuracy_mean: 0.8032, train_accuracy_std: 0.0463, train_loss_importance_vector_0_mean: 0.0200, train_loss_importance_vector_0_std: 0.0000, train_loss_importance_vector_1_mean: 0.0200, train_loss_importance_vector_1_std: 0.0000, train_loss_importance_vector_2_mean: 0.0200, train_loss_importance_vector_2_std: 0.0000, train_loss_importance_vector_3_mean: 0.0200, train_loss_importance_vector_3_std: 0.0000, train_loss_importance_vector_4_mean: 0.9200, train_loss_importance_vector_4_std: 0.0000, val_loss_mean: 9.2891, val_loss_std: 1.6362, val_accuracy_mean: 0.7851, val_accuracy_std: 0.0496, val_loss_importance_vector_0_mean: 0.0200, val_loss_importance_vector_0_std: 0.0000, val_loss_importance_vector_1_mean: 0.0200, val_loss_importance_vector_1_std: 0.0000, val_loss_importance_vector_2_mean: 0.0200, val_loss_importance_vector_2_std: 0.0000, val_loss_importance_vector_3_mean: 0.0200, val_loss_importance_vector_3_std: 0.0000, val_loss_importance_vector_4_mean: 0.9200, val_loss_importance_vector_4_std: 0.0000, 
train_seed 128038, val_seed: 128038, at pause time
